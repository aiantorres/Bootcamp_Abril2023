{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Homogeneidad de dos grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"./Datos/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./Datos/homogeneidad2grupos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo1=df[df.position==1.0]\n",
    "grupo2=df[df.position==2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levene?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H_0 : \\sigma_1 = \\sigma_2$$\n",
    "$$H_1: \\sigma_1 \\neq \\sigma_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levene(grupo1.salary,grupo2.salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levene(grupo1.salary,grupo2.salary,center=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios \n",
    "del fichero homogenidasd3grupo estudiar si tienen la misma varainza los tres o dos a dos.\n",
    "**Estudiad si tienen la misma media**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANN WHITNEY o Prueba U\n",
    "### Para detectar si dos grupos son independientes\n",
    "Por cada grupo necesitaremos más de 20 muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"./Datos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./Datos/forceps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Estadar son los Forceps=1\n",
    "* Jumbo son los Forceps=2\n",
    "¿diferencias significativas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo1=df[df.Forceps==1.0]\n",
    "grupo2=df[df.Forceps==2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitneyu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitneyu(grupo1.Resection,grupo2.Resection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo1.Resection.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H_0: \\mu_1 \\geq \\mu_2$$ \n",
    "$$ H_1: \\mu_1 < \\mu_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitneyu(grupo1.Resection,grupo2.Resection,alternative=\"less\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizad el fichero de salarios para ver que grupo tiene mayor sueldo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Como detectar si sigue una distribución normal\n",
    "## Manera gráfica\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(df[\"Resection\"],fit=True,line='q');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salarios=pd.read_csv(\"./Datos/homogeneidad2grupos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(salarios[\"salary\"],fit=True,line='q');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salarios=pd.read_csv(\"./Datos/homogeneidad3grupos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(salarios[\"salary\"],fit=True,line='q');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import normaltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normaltest(salarios[\"salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normaltest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import anderson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anderson(salarios.salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro(salarios.salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krustall Wallis\n",
    "Se realzia un estudio sobre drogas en el que se compara clasificaciomnes de dolor.\n",
    "Se suministran cuatro grupos de dosis:\n",
    "* valor1 100 mg\n",
    "* valor2 250 mg\n",
    "* valor3 500 mg\n",
    "* valor4 1000 mg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drogas=pd.read_csv('./Datos/drugstudy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drogas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drogas.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drogas.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drogas.dose.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo1=drogas[drogas.dose==1]\n",
    "grupo2=drogas[drogas.dose==2]\n",
    "grupo3=drogas[drogas.dose==3]\n",
    "grupo4=drogas[drogas.dose==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drogas.groupby([\"dose\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal(grupo1.rating,grupo2.rating,grupo3.rating,grupo4.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estadistico,pvalor=kruskal(grupo1.rating,grupo2.rating,grupo3.rating,grupo4.rating)\n",
    "if pvalor>0.05:\n",
    "    print(\"No rechazamos H0\")\n",
    "else:\n",
    "    print(\"Rechazamos H0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\binom{4}{2} = \\cfrac{4!}{(2!(4-2)!)} = \\cfrac{4\\times 3}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rechazados={}\n",
    "Aceptados={}\n",
    "s=0\n",
    "h=0\n",
    "for i in range(1,4):\n",
    "    for j in range(i+1,5):\n",
    "        grupo1=drogas[drogas.dose==i]\n",
    "        grupo2=drogas[drogas.dose==j]\n",
    "        stat, p = mannwhitneyu(grupo1.rating,grupo2.rating,\n",
    "                               alternative='two-sided')\n",
    "        print(\"=\"*20)\n",
    "        if p > 0.05:\n",
    "            s+=1\n",
    "            Aceptados[s]=[i,j]\n",
    "            # print('No rechazamos H0: No hay diferencias significativas entre los grupos {0} y {1}.'.format(i,j))\n",
    "        else:\n",
    "            h+=1\n",
    "\t        # print('Rechazamos H0: Hay diferencias significativas entre los grupos {0} y {1}.'.format(i,j))\n",
    "            Rechazados[h]=[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rechazados={}\n",
    "Aceptados={}\n",
    "s=0\n",
    "for i,j in [(x,y) for x in drogas.dose.unique() for y in drogas.dose.unique() if x<y]:\n",
    "    s+=1\n",
    "    stat, p = mannwhitneyu(drogas[drogas.dose==i].rating,drogas[drogas.dose==j].rating,alternative='two-sided')\n",
    "    if p > 0.05:\n",
    "        Aceptados[s]=[i,j]\n",
    "    else:\n",
    "        Rechazados[s]=[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rechazados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aceptados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Wilcoxon\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./Datos/revenuedata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Q1      18 non-null     float64\n",
      " 1   Q2      18 non-null     float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 416.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>941415.166667</td>\n",
       "      <td>455134.520736</td>\n",
       "      <td>437477.0</td>\n",
       "      <td>531321.0</td>\n",
       "      <td>787176.0</td>\n",
       "      <td>1236987.25</td>\n",
       "      <td>1792376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>788682.777778</td>\n",
       "      <td>503100.254425</td>\n",
       "      <td>283875.0</td>\n",
       "      <td>388587.5</td>\n",
       "      <td>616081.5</td>\n",
       "      <td>972938.00</td>\n",
       "      <td>1820474.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count           mean            std       min       25%       50%  \\\n",
       "Q1   18.0  941415.166667  455134.520736  437477.0  531321.0  787176.0   \n",
       "Q2   18.0  788682.777778  503100.254425  283875.0  388587.5  616081.5   \n",
       "\n",
       "           75%        max  \n",
       "Q1  1236987.25  1792376.0  \n",
       "Q2   972938.00  1820474.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>528819.0</td>\n",
       "      <td>329778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1263689.0</td>\n",
       "      <td>504738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1172512.0</td>\n",
       "      <td>989454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1647341.0</td>\n",
       "      <td>1465183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>528419.0</td>\n",
       "      <td>351158.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Q1         Q2\n",
       "0   528819.0   329778.0\n",
       "1  1263689.0   504738.0\n",
       "2  1172512.0   989454.0\n",
       "3  1647341.0  1465183.0\n",
       "4   528419.0   351158.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import normal_ad\n",
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7254672844627201, 0.047903777406905844)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_ad(df.Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.8859636187553406, pvalue=0.032929033041000366)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapiro(df.Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.062961278378065, 0.00643096243773041)\n",
      "ShapiroResult(statistic=0.8476520776748657, pvalue=0.007778363302350044)\n"
     ]
    }
   ],
   "source": [
    "print(normal_ad(df.Q2))\n",
    "print(shapiro(df.Q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mwilcoxon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mzero_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wilcox'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcorrection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0malternative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'two-sided'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Calculate the Wilcoxon signed-rank test.\n",
      "\n",
      "The Wilcoxon signed-rank test tests the null hypothesis that two\n",
      "related paired samples come from the same distribution. In particular,\n",
      "it tests whether the distribution of the differences x - y is symmetric\n",
      "about zero. It is a non-parametric version of the paired T-test.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "x : array_like\n",
      "    Either the first set of measurements (in which case ``y`` is the second\n",
      "    set of measurements), or the differences between two sets of\n",
      "    measurements (in which case ``y`` is not to be specified.)  Must be\n",
      "    one-dimensional.\n",
      "y : array_like, optional\n",
      "    Either the second set of measurements (if ``x`` is the first set of\n",
      "    measurements), or not specified (if ``x`` is the differences between\n",
      "    two sets of measurements.)  Must be one-dimensional.\n",
      "zero_method : {\"pratt\", \"wilcox\", \"zsplit\"}, optional\n",
      "    The following options are available (default is \"wilcox\"):\n",
      "\n",
      "      * \"pratt\": Includes zero-differences in the ranking process,\n",
      "        but drops the ranks of the zeros, see [4]_, (more conservative).\n",
      "      * \"wilcox\": Discards all zero-differences, the default.\n",
      "      * \"zsplit\": Includes zero-differences in the ranking process and\n",
      "        split the zero rank between positive and negative ones.\n",
      "correction : bool, optional\n",
      "    If True, apply continuity correction by adjusting the Wilcoxon rank\n",
      "    statistic by 0.5 towards the mean value when computing the\n",
      "    z-statistic if a normal approximation is used.  Default is False.\n",
      "alternative : {\"two-sided\", \"greater\", \"less\"}, optional\n",
      "    The alternative hypothesis to be tested, see Notes. Default is\n",
      "    \"two-sided\".\n",
      "mode : {\"auto\", \"exact\", \"approx\"}\n",
      "    Method to calculate the p-value, see Notes. Default is \"auto\".\n",
      "\n",
      "Returns\n",
      "-------\n",
      "statistic : float\n",
      "    If ``alternative`` is \"two-sided\", the sum of the ranks of the\n",
      "    differences above or below zero, whichever is smaller.\n",
      "    Otherwise the sum of the ranks of the differences above zero.\n",
      "pvalue : float\n",
      "    The p-value for the test depending on ``alternative`` and ``mode``.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "kruskal, mannwhitneyu\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The test has been introduced in [4]_. Given n independent samples\n",
      "(xi, yi) from a bivariate distribution (i.e. paired samples),\n",
      "it computes the differences di = xi - yi. One assumption of the test\n",
      "is that the differences are symmetric, see [2]_.\n",
      "The two-sided test has the null hypothesis that the median of the\n",
      "differences is zero against the alternative that it is different from\n",
      "zero. The one-sided test has the null hypothesis that the median is\n",
      "positive against the alternative that it is negative\n",
      "(``alternative == 'less'``), or vice versa (``alternative == 'greater.'``).\n",
      "\n",
      "To derive the p-value, the exact distribution (``mode == 'exact'``)\n",
      "can be used for sample sizes of up to 25. The default ``mode == 'auto'``\n",
      "uses the exact distribution if there are at most 25 observations and no\n",
      "ties, otherwise a normal approximation is used (``mode == 'approx'``).\n",
      "\n",
      "The treatment of ties can be controlled by the parameter `zero_method`.\n",
      "If ``zero_method == 'pratt'``, the normal approximation is adjusted as in\n",
      "[5]_. A typical rule is to require that n > 20 ([2]_, p. 383).\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test\n",
      ".. [2] Conover, W.J., Practical Nonparametric Statistics, 1971.\n",
      ".. [3] Pratt, J.W., Remarks on Zeros and Ties in the Wilcoxon Signed\n",
      "   Rank Procedures, Journal of the American Statistical Association,\n",
      "   Vol. 54, 1959, pp. 655-667. :doi:`10.1080/01621459.1959.10501526`\n",
      ".. [4] Wilcoxon, F., Individual Comparisons by Ranking Methods,\n",
      "   Biometrics Bulletin, Vol. 1, 1945, pp. 80-83. :doi:`10.2307/3001968`\n",
      ".. [5] Cureton, E.E., The Normal Approximation to the Signed-Rank\n",
      "   Sampling Distribution When Zero Differences are Present,\n",
      "   Journal of the American Statistical Association, Vol. 62, 1967,\n",
      "   pp. 1068-1069. :doi:`10.1080/01621459.1967.10500917`\n",
      "\n",
      "Examples\n",
      "--------\n",
      "In [4]_, the differences in height between cross- and self-fertilized\n",
      "corn plants is given as follows:\n",
      "\n",
      ">>> d = [6, 8, 14, 16, 23, 24, 28, 29, 41, -48, 49, 56, 60, -67, 75]\n",
      "\n",
      "Cross-fertilized plants appear to be be higher. To test the null\n",
      "hypothesis that there is no height difference, we can apply the\n",
      "two-sided test:\n",
      "\n",
      ">>> from scipy.stats import wilcoxon\n",
      ">>> w, p = wilcoxon(d)\n",
      ">>> w, p\n",
      "(24.0, 0.041259765625)\n",
      "\n",
      "Hence, we would reject the null hypothesis at a confidence level of 5%,\n",
      "concluding that there is a difference in height between the groups.\n",
      "To confirm that the median of the differences can be assumed to be\n",
      "positive, we use:\n",
      "\n",
      ">>> w, p = wilcoxon(d, alternative='greater')\n",
      ">>> w, p\n",
      "(96.0, 0.0206298828125)\n",
      "\n",
      "This shows that the null hypothesis that the median is negative can be\n",
      "rejected at a confidence level of 5% in favor of the alternative that\n",
      "the median is greater than zero. The p-values above are exact. Using the\n",
      "normal approximation gives very similar values:\n",
      "\n",
      ">>> w, p = wilcoxon(d, mode='approx')\n",
      ">>> w, p\n",
      "(24.0, 0.04088813291185591)\n",
      "\n",
      "Note that the statistic changed to 96 in the one-sided case (the sum\n",
      "of ranks of positive differences) whereas it is 24 in the two-sided\n",
      "case (the minimum of sum of ranks above and below zero).\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\daniel montes\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "wilcoxon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=32.0, pvalue=0.0182342529296875)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(df.Q1,df.Q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H_0: P(X>Y) \\leq P(Y>X)$$\n",
    "$$ H_1: P(X>Y) > P(Y>X)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=139.0, pvalue=0.992034912109375)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(df.Q1,df.Q2,alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>528819.0</td>\n",
       "      <td>329778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1263689.0</td>\n",
       "      <td>504738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1172512.0</td>\n",
       "      <td>989454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1647341.0</td>\n",
       "      <td>1465183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>528419.0</td>\n",
       "      <td>351158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>505763.0</td>\n",
       "      <td>342215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>437477.0</td>\n",
       "      <td>283875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>452378.0</td>\n",
       "      <td>308403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>764158.0</td>\n",
       "      <td>629594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1792376.0</td>\n",
       "      <td>1707832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>608359.0</td>\n",
       "      <td>602569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>736464.0</td>\n",
       "      <td>790142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1116448.0</td>\n",
       "      <td>500876.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1062181.0</td>\n",
       "      <td>510291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1721589.0</td>\n",
       "      <td>1820474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>810194.0</td>\n",
       "      <td>923390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>538827.0</td>\n",
       "      <td>659898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1258479.0</td>\n",
       "      <td>1476420.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Q1         Q2\n",
       "0    528819.0   329778.0\n",
       "1   1263689.0   504738.0\n",
       "2   1172512.0   989454.0\n",
       "3   1647341.0  1465183.0\n",
       "4    528419.0   351158.0\n",
       "5    505763.0   342215.0\n",
       "6    437477.0   283875.0\n",
       "7    452378.0   308403.0\n",
       "8    764158.0   629594.0\n",
       "9   1792376.0  1707832.0\n",
       "10   608359.0   602569.0\n",
       "11   736464.0   790142.0\n",
       "12  1116448.0   500876.0\n",
       "13  1062181.0   510291.0\n",
       "14  1721589.0  1820474.0\n",
       "15   810194.0   923390.0\n",
       "16   538827.0   659898.0\n",
       "17  1258479.0  1476420.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df#.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $H_0$: la probabilidad de una obsrvación de la primera poblacion X sea mayor que una observacion de la segunda  poblacióin Y es igual a a la probabilidad de que una obsrvación de la segunda poblacion Y sea mayor que una observacion de la primera poblacióin X $$P(X>Y)=P(Y>X)$$\n",
    "\n",
    "* $H_1$: la probabilidad de una obsrvación de la primera poblacion X sea mayor que una observacion de la segunda  poblacióin Y  no es igual a a la probabilidad de que una obsrvación de la segunda poblacion Y sea mayor que una observacion de la primera poblacióin X $$P(X>Y)\\neq P(Y>X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friedman\n",
    "es al aalterniativa no parametrica de la ANOVA.\n",
    "Es una extension del anterior.\n",
    "Se utiliza para estudiar por ejemplo el rendimiento de grupos .\n",
    "* Si los futbolistas estan en mejor forma en en cada estación.\n",
    "* Si los empleados dependiendo del día de la semana son más eficaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vino=pd.read_csv('./Datos/wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judge</th>\n",
       "      <th>pinecreek</th>\n",
       "      <th>saintjude</th>\n",
       "      <th>northnapa</th>\n",
       "      <th>sevenwinds</th>\n",
       "      <th>eternalvalley</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Judge  pinecreek  saintjude  northnapa  sevenwinds  eternalvalley\n",
       "0    1.0        6.0        3.0        3.0         5.0            3.0\n",
       "1    2.0        7.0        4.0        4.0         4.0            4.0\n",
       "2    3.0        6.0        5.0        4.0         5.0            3.0\n",
       "3    4.0        7.0        3.0        2.0         4.0            2.0\n",
       "4    5.0        5.0        4.0        3.0         4.0            4.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import friedmanchisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FriedmanchisquareResult(statistic=29.893491124260347, pvalue=5.144971162191748e-06)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friedmanchisquare(Vino.pinecreek,\n",
    "Vino.saintjude,\n",
    "Vino.northnapa,\n",
    "Vino.sevenwinds,\n",
    "Vino.eternalvalley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eternalvalley'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel Montes\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "c:\\Users\\Daniel Montes\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:3155: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "Rechazados={}\n",
    "Aceptados={}\n",
    "s=0\n",
    "for i,j in [(x,y) for x in range(1,6) for y in range(1,6) if x<y]:\n",
    "    s+=1\n",
    "    stat, p = wilcoxon(Vino[Vino.columns[i]],Vino[Vino.columns[j]],alternative='two-sided')\n",
    "    if p > 0.05:\n",
    "        Aceptados[s]=[Vino.columns[i],Vino.columns[j]]\n",
    "    else:\n",
    "        Rechazados[s]=[Vino.columns[i],Vino.columns[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: ['saintjude', 'northnapa'],\n",
       " 6: ['saintjude', 'sevenwinds'],\n",
       " 7: ['saintjude', 'eternalvalley'],\n",
       " 9: ['northnapa', 'eternalvalley']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aceptados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['pinecreek', 'saintjude'],\n",
       " 2: ['pinecreek', 'northnapa'],\n",
       " 3: ['pinecreek', 'sevenwinds'],\n",
       " 4: ['pinecreek', 'eternalvalley'],\n",
       " 8: ['northnapa', 'sevenwinds'],\n",
       " 10: ['sevenwinds', 'eternalvalley']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rechazados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## coeficiente de correlacion de spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mspearmanr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnan_policy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'propagate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0malternative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'two-sided'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Calculate a Spearman correlation coefficient with associated p-value.\n",
      "\n",
      "The Spearman rank-order correlation coefficient is a nonparametric measure\n",
      "of the monotonicity of the relationship between two datasets. Unlike the\n",
      "Pearson correlation, the Spearman correlation does not assume that both\n",
      "datasets are normally distributed. Like other correlation coefficients,\n",
      "this one varies between -1 and +1 with 0 implying no correlation.\n",
      "Correlations of -1 or +1 imply an exact monotonic relationship. Positive\n",
      "correlations imply that as x increases, so does y. Negative correlations\n",
      "imply that as x increases, y decreases.\n",
      "\n",
      "The p-value roughly indicates the probability of an uncorrelated system\n",
      "producing datasets that have a Spearman correlation at least as extreme\n",
      "as the one computed from these datasets. The p-values are not entirely\n",
      "reliable but are probably reasonable for datasets larger than 500 or so.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "a, b : 1D or 2D array_like, b is optional\n",
      "    One or two 1-D or 2-D arrays containing multiple variables and\n",
      "    observations. When these are 1-D, each represents a vector of\n",
      "    observations of a single variable. For the behavior in the 2-D case,\n",
      "    see under ``axis``, below.\n",
      "    Both arrays need to have the same length in the ``axis`` dimension.\n",
      "axis : int or None, optional\n",
      "    If axis=0 (default), then each column represents a variable, with\n",
      "    observations in the rows. If axis=1, the relationship is transposed:\n",
      "    each row represents a variable, while the columns contain observations.\n",
      "    If axis=None, then both arrays will be raveled.\n",
      "nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "    Defines how to handle when input contains nan.\n",
      "    The following options are available (default is 'propagate'):\n",
      "\n",
      "    * 'propagate': returns nan\n",
      "    * 'raise': throws an error\n",
      "    * 'omit': performs the calculations ignoring nan values\n",
      "\n",
      "alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "    Defines the alternative hypothesis. Default is 'two-sided'.\n",
      "    The following options are available:\n",
      "\n",
      "    * 'two-sided': the correlation is nonzero\n",
      "    * 'less': the correlation is negative (less than zero)\n",
      "    * 'greater':  the correlation is positive (greater than zero)\n",
      "\n",
      "    .. versionadded:: 1.7.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "correlation : float or ndarray (2-D square)\n",
      "    Spearman correlation matrix or correlation coefficient (if only 2\n",
      "    variables are given as parameters. Correlation matrix is square with\n",
      "    length equal to total number of variables (columns or rows) in ``a``\n",
      "    and ``b`` combined.\n",
      "pvalue : float\n",
      "    The p-value for a hypothesis test whose null hypotheisis\n",
      "    is that two sets of data are uncorrelated. See `alternative` above\n",
      "    for alternative hypotheses. `pvalue` has the same\n",
      "    shape as `correlation`.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard\n",
      "   Probability and Statistics Tables and Formulae. Chapman & Hall: New\n",
      "   York. 2000.\n",
      "   Section  14.7\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from scipy import stats\n",
      ">>> stats.spearmanr([1,2,3,4,5], [5,6,7,8,7])\n",
      "SpearmanrResult(correlation=0.82078..., pvalue=0.08858...)\n",
      ">>> rng = np.random.default_rng()\n",
      ">>> x2n = rng.standard_normal((100, 2))\n",
      ">>> y2n = rng.standard_normal((100, 2))\n",
      ">>> stats.spearmanr(x2n)\n",
      "SpearmanrResult(correlation=-0.07960396039603959, pvalue=0.4311168705769747)\n",
      ">>> stats.spearmanr(x2n[:,0], x2n[:,1])\n",
      "SpearmanrResult(correlation=-0.07960396039603959, pvalue=0.4311168705769747)\n",
      ">>> rho, pval = stats.spearmanr(x2n, y2n)\n",
      ">>> rho\n",
      "array([[ 1.        , -0.07960396, -0.08314431,  0.09662166],\n",
      "       [-0.07960396,  1.        , -0.14448245,  0.16738074],\n",
      "       [-0.08314431, -0.14448245,  1.        ,  0.03234323],\n",
      "       [ 0.09662166,  0.16738074,  0.03234323,  1.        ]])\n",
      ">>> pval\n",
      "array([[0.        , 0.43111687, 0.41084066, 0.33891628],\n",
      "       [0.43111687, 0.        , 0.15151618, 0.09600687],\n",
      "       [0.41084066, 0.15151618, 0.        , 0.74938561],\n",
      "       [0.33891628, 0.09600687, 0.74938561, 0.        ]])\n",
      ">>> rho, pval = stats.spearmanr(x2n.T, y2n.T, axis=1)\n",
      ">>> rho\n",
      "array([[ 1.        , -0.07960396, -0.08314431,  0.09662166],\n",
      "       [-0.07960396,  1.        , -0.14448245,  0.16738074],\n",
      "       [-0.08314431, -0.14448245,  1.        ,  0.03234323],\n",
      "       [ 0.09662166,  0.16738074,  0.03234323,  1.        ]])\n",
      ">>> stats.spearmanr(x2n, y2n, axis=None)\n",
      "SpearmanrResult(correlation=0.044981624540613524, pvalue=0.5270803651336189)\n",
      ">>> stats.spearmanr(x2n.ravel(), y2n.ravel())\n",
      "SpearmanrResult(correlation=0.044981624540613524, pvalue=0.5270803651336189)\n",
      "\n",
      ">>> rng = np.random.default_rng()\n",
      ">>> xint = rng.integers(10, size=(100, 2))\n",
      ">>> stats.spearmanr(xint)\n",
      "SpearmanrResult(correlation=0.09800224850707953, pvalue=0.3320271757932076)\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\daniel montes\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "spearmanr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "forc=pd.read_csv('./Datos/forceps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Forceps</th>\n",
       "      <th>Resection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Forceps  Resection\n",
       "0      2.0        2.0\n",
       "1      1.0        2.0\n",
       "2      2.0        3.0\n",
       "3      1.0        1.0\n",
       "4      1.0        2.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.4905700574607901, pvalue=0.023951568341931413)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(forc.Forceps,forc.Resection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$ correlacion no significativa $\\to$ muestras están incorreladas\n",
    "\n",
    "\n",
    "$H_1$ correlacion es significativa $\\to$ muestras están correladas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1eae6cefbe0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(forc.Forceps,forc.Resection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendall o $\\tau$-Kendall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mkendalltau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minitial_lexsort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnan_policy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'propagate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvariant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Calculate Kendall's tau, a correlation measure for ordinal data.\n",
      "\n",
      "Kendall's tau is a measure of the correspondence between two rankings.\n",
      "Values close to 1 indicate strong agreement, and values close to -1\n",
      "indicate strong disagreement. This implements two variants of Kendall's\n",
      "tau: tau-b (the default) and tau-c (also known as Stuart's tau-c). These\n",
      "differ only in how they are normalized to lie within the range -1 to 1;\n",
      "the hypothesis tests (their p-values) are identical. Kendall's original\n",
      "tau-a is not implemented separately because both tau-b and tau-c reduce\n",
      "to tau-a in the absence of ties.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "x, y : array_like\n",
      "    Arrays of rankings, of the same shape. If arrays are not 1-D, they\n",
      "    will be flattened to 1-D.\n",
      "initial_lexsort : bool, optional\n",
      "    Unused (deprecated).\n",
      "nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "    Defines how to handle when input contains nan.\n",
      "    The following options are available (default is 'propagate'):\n",
      "\n",
      "      * 'propagate': returns nan\n",
      "      * 'raise': throws an error\n",
      "      * 'omit': performs the calculations ignoring nan values\n",
      "\n",
      "method : {'auto', 'asymptotic', 'exact'}, optional\n",
      "    Defines which method is used to calculate the p-value [5]_.\n",
      "    The following options are available (default is 'auto'):\n",
      "\n",
      "      * 'auto': selects the appropriate method based on a trade-off\n",
      "        between speed and accuracy\n",
      "      * 'asymptotic': uses a normal approximation valid for large samples\n",
      "      * 'exact': computes the exact p-value, but can only be used if no ties\n",
      "        are present. As the sample size increases, the 'exact' computation\n",
      "        time may grow and the result may lose some precision.\n",
      "\n",
      "variant: {'b', 'c'}, optional\n",
      "    Defines which variant of Kendall's tau is returned. Default is 'b'.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "correlation : float\n",
      "   The tau statistic.\n",
      "pvalue : float\n",
      "   The two-sided p-value for a hypothesis test whose null hypothesis is\n",
      "   an absence of association, tau = 0.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "spearmanr : Calculates a Spearman rank-order correlation coefficient.\n",
      "theilslopes : Computes the Theil-Sen estimator for a set of points (x, y).\n",
      "weightedtau : Computes a weighted version of Kendall's tau.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The definition of Kendall's tau that is used is [2]_::\n",
      "\n",
      "  tau_b = (P - Q) / sqrt((P + Q + T) * (P + Q + U))\n",
      "\n",
      "  tau_c = 2 (P - Q) / (n**2 * (m - 1) / m)\n",
      "\n",
      "where P is the number of concordant pairs, Q the number of discordant\n",
      "pairs, T the number of ties only in `x`, and U the number of ties only in\n",
      "`y`.  If a tie occurs for the same pair in both `x` and `y`, it is not\n",
      "added to either T or U. n is the total number of samples, and m is the\n",
      "number of unique values in either `x` or `y`, whichever is smaller.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] Maurice G. Kendall, \"A New Measure of Rank Correlation\", Biometrika\n",
      "       Vol. 30, No. 1/2, pp. 81-93, 1938.\n",
      ".. [2] Maurice G. Kendall, \"The treatment of ties in ranking problems\",\n",
      "       Biometrika Vol. 33, No. 3, pp. 239-251. 1945.\n",
      ".. [3] Gottfried E. Noether, \"Elements of Nonparametric Statistics\", John\n",
      "       Wiley & Sons, 1967.\n",
      ".. [4] Peter M. Fenwick, \"A new data structure for cumulative frequency\n",
      "       tables\", Software: Practice and Experience, Vol. 24, No. 3,\n",
      "       pp. 327-336, 1994.\n",
      ".. [5] Maurice G. Kendall, \"Rank Correlation Methods\" (4th Edition),\n",
      "       Charles Griffin & Co., 1970.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from scipy import stats\n",
      ">>> x1 = [12, 2, 1, 12, 2]\n",
      ">>> x2 = [1, 4, 7, 1, 0]\n",
      ">>> tau, p_value = stats.kendalltau(x1, x2)\n",
      ">>> tau\n",
      "-0.47140452079103173\n",
      ">>> p_value\n",
      "0.2827454599327748\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\daniel montes\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "kendalltau?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=0.4572176441790554, pvalue=0.028242887576206643)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendalltau(forc.Resection,forc.Forceps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$ correlacion no significativa $\\to$ muestras están incorreladas\n",
    "\n",
    "\n",
    "$H_1$ correlacion es significativa $\\to$ muestras están correladas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
